# Logistic 回归概述

**Logistic 回归**是一种常用于**分类问题**的统计模型，特别适合用于**二分类任务**（如是/否、成功/失败等）。与线性回归不同，Logistic 回归的目标是预测**某个事件发生的概率**，并将预测结果映射到 $[0, 1]$ 之间。

常见的应用场景包括：

\- **预测病人是否患有某种疾病（是/否）**

\- 判断电子邮件是否为垃圾邮件（是/否）

\- 客户是否会流失（是/否）

------------------------------------------------------------------------

## **1. 模型公式**

Logistic 回归的核心在于将线性回归模型的输出结果经过 **Logistic 函数**（也称为**Sigmoid 函数**）的变换，使其落在 $[0, 1]$ 区间。

### **线性部分：**

$$
z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n
$$ 其中：

\- $z$ 是线性回归的输出值（可能为任何实数）

\- $x_i$ 是第 $i$ 个自变量

\- $\beta_i$ 是对应自变量的回归系数，表示自变量对目标事件的**对数几率** (log-odds) 的影响

### Logistic回归：

将线性回归的结果 $z$ 转换为概率 $p$： $$
p = \frac{1}{1 + e^{-z}}
$$ 该函数的输出 $p$ 为某个事件（如成功或分类为 1）发生的**概率**，满足 $0 \leq p \leq 1$。

------------------------------------------------------------------------

## 2. 概率与二分类

由于 Logistic 回归的输出是一个概率值 $p$，我们可以基于一个**阈值**（通常为 0.5）来进行二分类：

\- 如果 $p \geq 0.5$，预测类别为 1（事件发生）

\- 如果 $p < 0.5$，预测类别为 0（事件不发生）

------------------------------------------------------------------------

## 3. 估计系数：极大似然估计

在 Logistic 回归中，**回归系数** $\beta_0, \beta_1, \dots, \beta_n$ 通过**极大似然估计**（Maximum Likelihood Estimation, MLE）来求解，目的是找到一组系数，使模型预测的概率最符合实际数据。

------------------------------------------------------------------------

## 4. 结果解读

一个典型的 Logistic 回归输出会包括如下内容：

### **Coefficients (系数)**

每个自变量的系数（**Estimate**）反映了该变量对目标变量的**对数几率（log-odds）**的影响。系数的符号和大小说明：

\- **正系数**：增加该变量的值会增加预测事件发生的概率（即 $p$ 增大）。

\- **负系数**：增加该变量的值会减少预测事件发生的概率（即 $p$ 减小）。

### **Odds 和 Log-Odds**

-   **Odds（几率）**：某事件发生的概率与不发生的概率之比，即 $\text{Odds} = \frac{p}{1 - p}$。
-   **Log-Odds（对数几率）**：$\log(\text{Odds}) = z$。

自变量的系数直接反映的是对数几率的变化。

------------------------------------------------------------------------

## 5. 假设检验与 P 值

-   **z-value**：每个系数的 z 统计量，衡量其显著性。
-   **P 值**：检验系数是否显著不同于 0。如果 P 值 \< 0.05，我们可以认为该系数在统计上显著。

------------------------------------------------------------------------

## 6. 常见性能指标

在分类任务中，我们通常使用以下指标评估 Logistic 回归的性能：

\- **准确率 (Accuracy)**：正确分类的样本占总样本的比例 - **精确率 (Precision)**：预测为正类的样本中，实际为正类的比例

\- **召回率 (Recall)**：实际为正类的样本中，被正确预测为正类的比例

\- **ROC 曲线和 AUC**：衡量模型的分类能力，AUC 越接近 1 越好

------------------------------------------------------------------------

## 7. 示例：Logistic 回归的 R 代码

假设我们有一个数据集 `data`，包含是否患病的二分类变量 `disease` 和两个自变量 `age` 和 `bmi`，我们可以使用以下 R 代码来拟合 Logistic 回归模型：

``` r
# 拟合 Logistic 回归模型
model <- glm(disease ~ age + bmi, family = binomial(), data = data)

# 查看模型结果
summary(model)
```

输出的结果可能类似于：

```         
Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -3.5432   0.5674    -6.245  < 2e-16 ***
age          0.0456   0.0123     3.707  0.00021 ***
bmi          0.0671   0.0211     3.179  0.00148 ** 
```

解释：

\- 截距为 -3.5432，意味着当 `age` 和 `bmi` 都为 0 时，预测的对数几率为 -3.5432。

\- 年龄（`age`）每增加 1 单位，对数几率增加 0.0456，表明年龄越大，患病的概率越高。

\- BMI 每增加 1 单位，对数几率增加 0.0671，表明 BMI 越高，患病概率越大。

**对数几率为正数时，表明正相关；对数几率为负数时，表明负相关。**

------------------------------------------------------------------------

## 8. 总结

Logistic 回归是一种简单但功能强大的分类算法，广泛应用于医疗、金融等领域。它的优势在于：

\- **易解释**：模型系数能直接解释变量的影响方向和强度。

\- **适用性强**：适合二分类问题，并能自然处理概率输出。

# Example

```{r}
# family: 
glm_model <- glm(year ~ mpg + displacement + weight, family = poisson(), data = cars)
summary(glm_model)
```
