# 多变量线性回归

**多变量线性回归**是一种用于预测**连续型因变量**（如房价、销售额）的方法，它描述了因变量与多个自变量之间的**线性关系**。与简单线性回归不同，多变量线性回归处理多个自变量，适合更复杂的预测问题。

------------------------------------------------------------------------

## **1. 模型公式**

多变量线性回归模型的公式为： $$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \varepsilon
$$

其中：

\- $y$ 是因变量（我们想要预测的目标）。

\- $x_i$ 是第 $i$ 个自变量。

\- $\beta_i$ 是自变量 $x_i$ 的回归系数，反映该变量对因变量的影响。

\- $\varepsilon$ 是误差项，用于描述模型预测值与实际值之间的差异。

------------------------------------------------------------------------

## **2. 模型目标**

多变量线性回归的目标是找到一组回归系数 $\beta_0, \beta_1, \dots, \beta_n$，使模型的**预测误差最小**，即模型尽可能准确地拟合数据。

------------------------------------------------------------------------

## **3. 损失函数**

模型通过**最小二乘法 (Ordinary Least Squares, OLS)** 最小化以下损失函数： $$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
$$ - $MSE$ 表示均方误差（Mean Squared Error）。 - $y_i$ 是实际值，$\hat{y_i}$ 是模型预测值。

------------------------------------------------------------------------

## **4. 假设条件**

多变量线性回归需要满足以下假设条件：

1\. **线性关系**：因变量与自变量之间存在线性关系。

2\. **独立性**：自变量之间彼此独立，误差项也独立。

3\. **正态性**：误差项服从正态分布。

4\. **同方差性**：误差项的方差保持一致（即不存在异方差性）。

5\. **无多重共线性**：自变量之间不应存在较强的相关性。

------------------------------------------------------------------------

## **5. 回归系数的解释**

-   **系数** $\beta_i$：表示自变量 $x_i$ 每增加 1 个单位时，因变量 $y$ 增加或减少的平均值。\
-   **截距** $\beta_0$：表示所有自变量取值为 0 时，因变量的预测值。

------------------------------------------------------------------------

## **6. 示例：R 语言中的多变量线性回归**

假设我们有一个包含房价 (`price`)、面积 (`size`)、卧室数 (`bedrooms`) 和房龄 (`age`) 的数据集，使用 R 语言拟合多变量线性回归模型：

``` r
# 拟合多变量线性回归模型
model <- lm(price ~ size + bedrooms + age, data = housing_data)

# 查看模型摘要
summary(model)
```

可能的输出：

```         
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 50000.00  3000.00   16.67   < 2e-16 ***
size         150.00    10.00    15.00   < 2e-16 ***
bedrooms   -10000.00   500.00   -20.00  < 2e-16 ***
age         -500.00    50.00    -10.00  < 2e-16 ***
```

解释： - **`size`**：每增加 1 平方米，房价增加 150 元。 - **`bedrooms`**：每增加 1 个卧室，房价减少 10,000 元。 - **`age`**：房龄每增加 1 年，房价减少 500 元。

------------------------------------------------------------------------

## **7. 模型评价指标**

-   **R²（决定系数）**：表示自变量解释因变量变异的比例，范围为 0 到 1，值越大越好。
-   **调整后的 R²**：考虑了自变量数量的影响，更适合用于多变量回归。
-   **均方误差 (MSE)**：用于评估模型的预测误差。

------------------------------------------------------------------------

## **8. 多重共线性问题**

当自变量之间高度相关时，会出现**多重共线性**问题，导致模型不稳定。常用的检测方法包括： - **方差膨胀因子 (VIF)**：VIF \> 10 时表示多重共线性较强。

解决方案： - 移除相关性强的自变量。 - 使用**正则化回归**（如 Ridge 回归）。

------------------------------------------------------------------------

## **9. 优缺点**

### 优点：

-   简单易用，易于解释。
-   对数据的线性关系有很好的描述能力。

### 缺点：

-   无法处理非线性关系。
-   对异常值敏感。
-   假设条件严格（如同方差性）。

------------------------------------------------------------------------

## **10. 总结**

多变量线性回归是一种基础且广泛使用的回归方法，适合用于自变量与因变量之间存在**线性关系**的场景。它的易解释性使其成为统计建模的常用工具，但在处理复杂非线性数据时需要借助其他模型（如决策树或神经网络）。

------------------------------------------------------------------------

```{r}
model <- lm(year ~ mpg + displacement + weight, data = cars)
summary(model)
```
